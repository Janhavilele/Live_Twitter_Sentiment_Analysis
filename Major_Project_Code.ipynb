{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a0iEmm6ZQaJM"
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "from datetime import datetime, timedelta\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fqBBYeLOK5Qm"
   },
   "outputs": [],
   "source": [
    "# install Flair\n",
    "!pip install --upgrade git+https://github.com/flairNLP/flair.git\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TNfmTf0zKxb-"
   },
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "tagger = SequenceTagger.load('ner')\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AyISzvGDqbfu"
   },
   "outputs": [],
   "source": [
    "# Set connections\n",
    "api_key= \"ZlONrVgRmJoE26sERUjwZ4wk1\"\n",
    "api_key_secret=\"7L4l1nJtx8DjPBVbd0cZkj9zVOP2XdH087apwVKwvW86lJwjpo\"\n",
    "access_token=\"1465332733278703616-AgG1mIZxLmrWK9LHHCcoUIoNQW8bVp\"\n",
    "access_token_secret=\"27TxgQxJVqE62raMbBWs8l3w2KpVAhSthSapSa0lgUDu1\"\n",
    "bearer_token = \"AAAAAAAAAAAAAAAAAAAAABAlfQEAAAAAJj2GscccPak%2FPjXLK%2Fuhtq0gWjQ%3DGDK8lQJS1LE2fjcQba80lMKYK0CqwNVkIL1BDDnmv4qOxpUwYW\"\n",
    "\n",
    "# Use above credentials to authenticate the api\n",
    "auth = tweepy.OAuthHandler(api_key,api_key_secret)\n",
    "auth.set_access_token(access_token,access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bMRu_d24qbib",
    "outputId": "ecdb50cc-4949-410d-b878-cf70f3b44844"
   },
   "outputs": [],
   "source": [
    "# Create the dataframe to store the extracted data\n",
    "df = pd.DataFrame(columns=[\"Date\",\"User\",\"IsVerified\",\"Tweet\",\"Likes\",\"RT\",'User_location'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BAO3iVa-qblP"
   },
   "outputs": [],
   "source": [
    "# Function to extract the tweets\n",
    "\n",
    "def get_tweets(Topic,Count):    \n",
    "    i=0\n",
    "    for tweet in tweepy.Cursor(api.search, q=Topic,count=500, lang=\"en\",exclude='retweets').items():\n",
    "        print(i, end='\\r')\n",
    "        df.loc[i,\"Date\"] = tweet.created_at\n",
    "        df.loc[i,\"User\"] = tweet.user.name\n",
    "        df.loc[i,\"IsVerified\"] = tweet.user.verified\n",
    "        df.loc[i,\"Tweet\"] = tweet.text\n",
    "        df.loc[i,\"Likes\"] = tweet.favorite_count\n",
    "        df.loc[i,\"RT\"] = tweet.retweet_count\n",
    "        df.loc[i,\"User_location\"] = tweet.user.location\n",
    "        df.to_csv(\"TweetDataset.csv\",index=False)\n",
    "        df.to_excel('{}.xlsx'.format(\"TweetDataset\"),index=False)   ## Save as Excel\n",
    "        i=i+1\n",
    "        if i>Count:\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "8RQr_sS0qboK",
    "outputId": "5b41842d-e0ae-437b-f10f-478f43b7a3a2"
   },
   "outputs": [],
   "source": [
    "Topic=\"Tesla\" #@param {type:\"string\"}\n",
    "get_tweets(Topic , Count=500) \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJlRC8NZr9OT"
   },
   "source": [
    "Analyze the Tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "513Dev2Hqbtl"
   },
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "import re\n",
    "def clean_tweet(tweet):\n",
    "    return ' '.join(re.sub('(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|([RT])', ' ', str(tweet).lower()).split())\n",
    "\n",
    "# (@[A-Za-z0-9]+)   : Delete Anything like @hello @Letsupgrade etc\n",
    "# ([^0-9A-Za-z \\t]) : Delete everything other than text,number,space,tabspace\n",
    "# (\\w+:\\/\\/\\S+)     : Delete https://\n",
    "# ([RT]) : Remove \"RT\" from the tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "8pCbJ0iYqbxC",
    "outputId": "628a1c28-0440-4542-8fd4-4a24eb8c543a"
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "def analyze_sentiment(tweet):\n",
    "    analysis = TextBlob(tweet)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'Positive'\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Negative'\n",
    "\n",
    "hashtags = re.findall(r'#\\w+', row['tweet'])\n",
    "if len(hashtags) >= 1:\n",
    "  for hashtag in hashtags:\n",
    "    ners.append({ 'type': 'Hashtag', 'text': hashtag })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ubtHyNUtxE3"
   },
   "outputs": [],
   "source": [
    "def prepCloud(Topic_text,Topic):\n",
    "    Topic = str(Topic).lower()\n",
    "    Topic=' '.join(re.sub('([^0-9A-Za-z \\t])', ' ', Topic).split())\n",
    "    Topic = re.split(\"\\s+\",str(Topic))\n",
    "    stopwords = set(STOPWORDS)\n",
    "    stopwords.update(Topic) ### Add our topic in Stopwords, so it doesnt appear in wordClous\n",
    "    ###\n",
    "    text_new = \" \".join([txt for txt in Topic_text.split() if txt not in stopwords])\n",
    "    return text_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "zUvlXB-ItxHT",
    "outputId": "a25b4358-abbc-45ce-aee5-0351144428ac"
   },
   "outputs": [],
   "source": [
    "# Call function to get Clean tweets\n",
    "\n",
    "df['clean_tweet'] = df['Tweet'].apply(lambda x : clean_tweet(x))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "6FQHdmcKtxJ3",
    "outputId": "ca743499-3b08-4d34-a11c-20a9d3d6d0fe"
   },
   "outputs": [],
   "source": [
    "# call function to get the sentiments\n",
    "df[\"Sentiment\"] = df[\"Tweet\"].apply(lambda x : analyze_sentiment(x))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kevuPDwKtxMh",
    "outputId": "b5df87ae-c35b-41f8-9007-a6544adf8387"
   },
   "outputs": [],
   "source": [
    "# check summary of random record\n",
    "n = 10\n",
    "print(\"Original tweet:\\n\",df['Tweet'][n])\n",
    "print()\n",
    "print(\"Clean tweet:\\n\",df['clean_tweet'][n])\n",
    "print()\n",
    "print(\"Sentiment of the tweet:\\n\",df['Sentiment'][n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lHEUpoy9txP2",
    "outputId": "811ef707-9007-4bba-d20a-c36b359c4ba3"
   },
   "outputs": [],
   "source": [
    "# overall summary\n",
    "print(\"Total Tweets Extracted for Topic : {} are : {}\".format(Topic,len(df.Tweet)))\n",
    "print(\"Total Positive Tweets are : {}\".format(len(df[df[\"Sentiment\"]==\"Positive\"])))\n",
    "print(\"Total Negative Tweets are : {}\".format(len(df[df[\"Sentiment\"]==\"Negative\"])))\n",
    "print(\"Total Neutral Tweets are : {}\".format(len(df[df[\"Sentiment\"]==\"Neutral\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YA0sMKwqC6gf",
    "outputId": "be22ad7c-6f50-4ea6-aec4-9567f49a9bab"
   },
   "outputs": [],
   "source": [
    "df[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "cs_ANC5AC6jP",
    "outputId": "2996ac84-d02c-4baf-fec0-f2e3e75f55be"
   },
   "outputs": [],
   "source": [
    "sns.countplot(df[\"Sentiment\"])\n",
    "plt.title(\"Summary of Counts for Total tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "0WotPeozC6l7",
    "outputId": "b19db33f-ea96-46a9-ec83-e09bc8afcbe2"
   },
   "outputs": [],
   "source": [
    "a=len(df[df[\"Sentiment\"]==\"Positive\"])\n",
    "b=len(df[df[\"Sentiment\"]==\"Negative\"])\n",
    "c=len(df[df[\"Sentiment\"]==\"Neutral\"])\n",
    "d=np.array([a,b,c])\n",
    "explode = (0.1, 0.0, 0.1)\n",
    "plt.pie(d,shadow=True,explode=explode,labels=[\"Positive\",\"Negative\",\"Neutral\"],autopct='%1.2f%%');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bFhuX8hrSmS"
   },
   "source": [
    "Generate WordCloud\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
